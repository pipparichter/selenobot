{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "38dbe5cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cab96b5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/home/prichter/Documents/selenobot/src/')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d991967",
   "metadata": {},
   "source": [
    "# Detection task\n",
    "\n",
    "\"Detection task\" refers to the ability of the classifier to identify a sequence as either an erroneously-truncated selenoprotein, or a full-length non-selenoprotein. For this task, we used full-length negative normal proteins as negative test cases. The negative cases did *not* include full-length selenoproteins; we are basing this project on the observation that selenoproteins are misidentified, so full-length selenoproteins will not be present in the data we use to validate the model. The positive cases consisted of selenoproteins truncated at the *first* selenocysteine residue only. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8dbb67ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the data and figure directories. \n",
    "DATA_DIR = '/home/prichter/Documents/selenobot/data/uniprot_2023_03/detect' \n",
    "FIGURE_DIR = '/home/prichter/Documents/selenobot/figures/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "83f8a355",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.classifiers import EmbeddingClassifier, AacClassifier\n",
    "from src.dataset import get_dataloader\n",
    "from src.utils import csv_ids, csv_labels\n",
    "\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b3f595b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths where the train and test data are stored. \n",
    "train_path = os.path.join(DATA_DIR, 'train.csv')\n",
    "test_path = os.path.join(DATA_DIR, 'test.csv')\n",
    "val_path = os.path.join(DATA_DIR, 'val.csv')\n",
    "\n",
    "# First load the data into a dataset object. \n",
    "train_dataloader = get_dataloader(train_path, batch_size=256)\n",
    "val_dataloader = get_dataloader(val_path, batch_size=256)\n",
    "# test_dataloader = get_dataloader(test_path, batch_size=1024)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18f6f749",
   "metadata": {},
   "source": [
    "## Testing the benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "95ff974d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, try training with no other weight, to get a sense of how many epochs to use.\n",
    "model = AacClassifier()\n",
    "# model = EmbeddingClassifier(1024)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0f1fa27",
   "metadata": {},
   "source": [
    "I am curious about how the weight passed into the `WeightedBCELoss` will affect the performance on batches with selenoprotein relative to batches without selenoprotein. For now, I will test out different values on the `AacClassifier`, mostly to see if there *are* any loss function weights which might allow the model to decrease training loss on batches with and without selenoproteins simultaneously (or if this method of binary classification simply isn't sufficient). Based on some preliminary runs, it seems as though around 20 epochs is enough time for the `AacClassifier` to get about as good as it will get, so I will stick with this number for now. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0c7b7c52",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "classifiers.Classifier.train_: 100%|██████████| 15/15 [00:15<00:00,  1.04s/it, val_acc=0.33]\n"
     ]
    }
   ],
   "source": [
    "# aac_reporters = []\n",
    "# for bce_loss_weight in [1, 10, 100, 1000, 10000, 100000]:\n",
    "#     model.reset() # Reset the model weights. \n",
    "#     aac_reporter = model._train(train_dataloader, val=test_dataloader, epochs=1, lr=0.001, bce_loss_weight=bce_loss_weight)\n",
    "#     aac_reporters.append(aac_reporter)\n",
    "#     break\n",
    "\n",
    "model.reset()\n",
    "reporter = model._train(train_dataloader, val=val_dataloader, epochs=15, lr=0.001, bce_loss_weight=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "63729464",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'test_dataloader' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39msklearn\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mnumpy\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mnp\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m tn, fp, fn, tp \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mravel(sklearn\u001b[39m.\u001b[39mmetrics\u001b[39m.\u001b[39mconfusion_matrix(\u001b[39m*\u001b[39mmodel\u001b[39m.\u001b[39mpredict(test_dataloader)))\n\u001b[1;32m      5\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mtrue negative\u001b[39m\u001b[39m'\u001b[39m, tn)\n\u001b[1;32m      6\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mfalse positive\u001b[39m\u001b[39m'\u001b[39m, fp)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'test_dataloader' is not defined"
     ]
    }
   ],
   "source": [
    "import sklearn\n",
    "import numpy as np\n",
    "tn, fp, fn, tp = np.ravel(sklearn.metrics.confusion_matrix(*model.predict(test_dataloader)))\n",
    "\n",
    "print('true negative', tn)\n",
    "print('false positive', fp)\n",
    "print('false negative', fn)\n",
    "print('true positive', tp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49a38880",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plot_train_losses' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m plot_train_losses(infos, path\u001b[39m=\u001b[39mFIGURE_DIR \u001b[39m+\u001b[39m \u001b[39m'\u001b[39m\u001b[39memb_train_losses_pooled_batches_with_sec.png\u001b[39m\u001b[39m'\u001b[39m, title\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mEmbeddingClassifier pooled train losses on batches with selenoproteins\u001b[39m\u001b[39m'\u001b[39m, pool\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, sec_only\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m      2\u001b[0m plot_train_losses(infos, path\u001b[39m=\u001b[39mFIGURE_DIR \u001b[39m+\u001b[39m \u001b[39m'\u001b[39m\u001b[39memb_train_losses_pooled.png\u001b[39m\u001b[39m'\u001b[39m, title\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mEmbeddingClassifier pooled train losses\u001b[39m\u001b[39m'\u001b[39m, pool\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, sec_only\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[1;32m      3\u001b[0m plot_train_losses(infos, path\u001b[39m=\u001b[39mFIGURE_DIR \u001b[39m+\u001b[39m \u001b[39m'\u001b[39m\u001b[39memb_train_losses.png\u001b[39m\u001b[39m'\u001b[39m, title\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mEmbeddingClassifier train losses\u001b[39m\u001b[39m'\u001b[39m, pool\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, sec_only\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'plot_train_losses' is not defined"
     ]
    }
   ],
   "source": [
    "plot_train_losses(infos, path=FIGURE_DIR + 'emb_train_losses_pooled_batches_with_sec.png', title='EmbeddingClassifier pooled train losses on batches with selenoproteins', pool=False, sec_only=True)\n",
    "plot_train_losses(infos, path=FIGURE_DIR + 'emb_train_losses_pooled.png', title='EmbeddingClassifier pooled train losses', pool=True, sec_only=False)\n",
    "plot_train_losses(infos, path=FIGURE_DIR + 'emb_train_losses.png', title='EmbeddingClassifier train losses', pool=False, sec_only=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22852dc3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
