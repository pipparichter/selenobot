from prettytable import PrettyTable
import pandas as pd 
import numpy as np
import torch

import sys
sys.path.append('/home/prichter/Documents/selenobot/src')
from src.dataset import SequenceDataset
from src.esm import EsmClassifierV2, esm_test, esm_train
from src.bench import BenchmarkClassifier, BenchmarkTokenizer
from torch.utils.data import DataLoader
from transformers import EsmModel, EsmTokenizer, AutoTokenizer

from src.plot import *

figure_dir = '/home/prichter/Documents/selenobot/figures/'
data_dir = '/home/prichter/Documents/selenobot/data/'

import h5py

def get_h5_embedding(filename, keyset=None):
# def summary(model):
#     '''
#     Print out a summary of the model weights, and which parameters are trainable. 
#     '''
#     table = PrettyTable(['name', 'num_params', 'fixed'])

#     num_fixed = 0
#     num_total = 0

#     params = {}

#     for name, param in model.named_parameters():
#         num_params = param.numel()
#         fixed = str(not param.requires_grad)
#         table.add_row([name, num_params, fixed])

#         if not param.requires_grad:
#             num_fixed += num_params
        
#         num_total += num_params
    
#     print(table)
#     print('TOTAL:', num_total)
#     print('TRAINABLE:', num_total - num_fixed, f'({int(100 * (num_total - num_fixed)/num_total)}%)')


if __name__ == '__main__':

    train_data = pd.read_csv(data_dir + 'train.csv')
    test_data = pd.read_csv(data_dir + 'test.csv')
    
    train_embeddings_esm = np.loadtxt(data_dir + 'train_embeddings_esm.csv', delimiter=',')
    train_embeddings_acc = np.loadtxt(data_dir + 'train_embeddings_acc.csv', delimiter=',')
    test_embeddings_esm = np.loadtxt(data_dir + 'test_embeddings_esm.csv', delimiter=',')
    test_embeddings_acc = np.loadtxt(data_dir + 'test_embeddings_acc.csv', delimiter=',')
    
    # ------------------------------------------------------------------------------------------
    # One of the first things I want to do is see how the ESM-generated embeddings and the
    # ones generated by the BenchmarkTokenizer compare in lower-dimensional space. Can we see,
    # from the embeddings alone, differences in selenoproteins verus short proteins?

    # Should probably note that, if we can see a difference with the BenchmarkTokenizer alone, 
    # the ML models may just be picking up on differences in amino acid content. 
    # ------------------------------------------------------------------------------------------

    # # Get the category, i.e. selenocysteine-containing (1) or not (0)
    # categories = test_data['label'].values
    # labels = ['selenoprotein' if (x == 1) else 'control' for x in categories]
    
    # kwargs = {'labels':labels, 'n_points':300}
    # plot_embeddings(test_embeddings_esm, title='ESM embedding space', filename=figure_dir + 'embeddings_esm.png', **kwargs)
    # plot_embeddings(test_embeddings_acc, title='AAC embedding space', filename=figure_dir + 'embeddings_acc.png', **kwargs)

    # ------------------------------------------------------------------------------------------
    # Another thing I was curious about was how length presents in each embedding space (for a
    # sanity check, the lengths should seem pretty randomly scattered in ACC embedding space)
    # ------------------------------------------------------------------------------------------
    
    # lengths = map(len, test_data['seq']) # Get the lengths of each sequence. 
    # lengths = np.array(list(lengths))
    # min_length, max_length = min(lengths), max(lengths)
    # n_bins = 10
    # bins = np.linspace(min_length, max_length, n_bins).astype(int)
    # bins[-1] = bins[-1] + 1 # Account for the fact that the last bin is cut short. 
    # # Get the bin number of each length. 
    # bin_idxs = np.digitize(lengths, bins)
    
    # bin_labels = []
    # for i in range(len(bins) - 1):
    #     bin_labels.append(f'{bins[i]}<=x<{bins[i + 1]})')
    # labels = [bin_labels[i - 1] for i in bin_idxs]
    
    # kwargs = {'labels':labels, 'n_points':300}
    # plot_embeddings(test_embeddings_esm, title='ESM embedding space', filename=figure_dir + 'embeddings_esm_with_length.png', **kwargs)
    # plot_embeddings(test_embeddings_acc, title='AAC embedding space', filename=figure_dir + 'embeddings_aac_with_length.png', **kwargs)

    # ------------------------------------------------------------------------------------------
    # Another thing I wanted to check on is how the predictions made by different models map to
    # different embedding spaces. So, I am going to train each of the current model variations
    # (currently an embedding layer + linear classifier, simple logistic regression, and esm + linear
    # classifier), and plot where they give the correct predictions in each embedding space (i.e. the
    # one generated by ESM and the one from the BenchmarkTokenizer). Now that I am thinking about it, 
    # I should probably do something for the embedding layer of the LinearClassifier as well. 
    # ------------------------------------------------------------------------------------------
    
    # # BenchmarkClassifier ----------------------------------------------------------------------
     
    # # Load the DataLoader. 
    # kwargs = {'tokenizer':BenchmarkTokenizer()}
    # test_dataset = SequenceDataset(test_data, labels=test_data['label'].values, **kwargs)
    # train_dataset = SequenceDataset(train_data, labels=train_data['label'].values, **kwargs)

    # # NOTE: Should I be using the train data for the fitting step, for a valid comparison?
    # model = BenchmarkClassifier()
    # # model.fit(test_dataset.get_data(), test_dataset.get_labels()) 
    # model.fit(train_dataset.get_data(), train_dataset.get_labels()) 
    # preds, _ = model.predict(test_dataset.get_data())

    # print('ACCURACY:', (preds == test_dataset.get_labels()).mean().item())

    # # Label the data according to whether or not it was correctly or incorrectly classified. 
    # labels = ['correct' if x else 'incorrect' for x in (preds == test_dataset.get_labels())]
    
    # palette = {'correct':'green', 'incorrect':'red'}
    # kwargs = {'labels':labels, 'palette':palette, 'n_points':300}
    # plot_embeddings(test_embeddings_acc, title='BenchmarkClassifier predictions in AAC embedding space', filename=figure_dir + 'embeddings_aac_with_benchmark_predictions.png', **kwargs)
    # plot_embeddings(test_embeddings_esm, title='BenchmarkClassifier predictions in ESM embedding space', filename=figure_dir + 'embeddings_esm_with_benchmark_predictions.png', **kwargs)
    
    # # ------------------------------------------------------------------------------------------
    
    # # EsmClassifierV2 --------------------------------------------------------------------------
   # test_dataset = SequenceDataset(test_data, labels=test_data['label'].values, embeddings=test_embeddings_esm, **kwargs)
    # train_dataset = SequenceDataset(train_data, labels=train_data['label'].values, embeddings=train_embeddings_esm, **kwargs)

    # # Now use ESM V2 to generate the same plots. Load up the pre-trained model
    # test_dataloader = DataLoader(test_dataset, batch_size=128, shuffle=True)
    # train_dataloader = DataLoader(train_dataset, batch_size=128, shuffle=True)

    # # esm_v2_model = EsmClassifierV2()
    # # losses = esm_train(esm_v2_model, train_dataloader)
    # # torch.save(esm_v2_model, 'esm_v2_model.pickle') # Save the trained model. 

    # esm_v2_model = torch.load('/home/prichter/Documents/protex/esm_v2_model.pickle')
    # output = esm_test(esm_v2_model, test_dataloader)

    # # print('LOSS:', output['loss'])
    # print('ACCURACY:', (output['preds'] == output['labels']).float().mean().item())

    # # Label the data according to whether or not it was correctly or incorrectly classified. 
    # correct = (output['preds'].numpy() == output['labels'].numpy())
    # labels = ['correct' if x else 'incorrect' for x in correct]
    # labels = np.array(labels)
     
    # palette = {'correct':'green', 'incorrect':'red'}
    # plot_embeddings(test_embeddings_acc, labels=labels, title='ESMV2 predictions in AAC embedding space', n_points=300, filename=figure_dir + 'embeddings_aac_with_esmv2_prediction.png', palette=palette)
    # plot_embeddings(test_embeddings_esm, labels=labels, title='ESMV2 predictions in ESM embedding space', n_points=300, filename=figure_dir + 'embeddings_esm_with_esmv2_prediction.png', palette=palette)


    # ------------------------------------------------------------------------------------------
    # It's not a given that the ESM embeddings will actually be better than the embeddings we have
    # already generated (the Prot5 embeddings). I will try plugging the Prot5 embeddings into the model
    # (in place of the ESM embeddings). 
    # ------------------------------------------------------------------------------------------

    train_embeddings_prot5, _ = get_h5_embedding(data_dir + 'train.28Jul2023.embeddings.h5')
    train_embeddings_prot5 = train_embeddings_prot5.values
 
    test_embeddings_prot5, gene_names = get_h5_embedding(data_dir + 'test.28Jul2023.embeddings.h5')
    assert np.all(np.array(gene_names) == test_data['id'].values)
    test_embeddings_prot5 = test_embeddings_prot5.values

    
    # train_embeddings_prot5 = pd.read_hdf(data_dir + 'train.28Jul2023.embeddings.h5')
    # test_embeddings_prot5 = pd.read_hdf(data_dir + 'test.28Jul2023.embeddings.h5')
 
    tokenizer = AutoTokenizer.from_pretrained('facebook/esm2_t6_8M_UR50D')
    # Load in the train and test Datasets with pre-generated embeddings. 
    kwargs = {'tokenizer':tokenizer, 'return_tensors':'pt', 'padding':True, 'truncation':True}
    test_dataset = SequenceDataset(test_data, labels=test_data['label'].values, embeddings=test_embeddings_prot5, **kwargs)
    train_dataset = SequenceDataset(train_data, labels=train_data['label'].values, embeddings=train_embeddings_prot5, **kwargs)

    # Now use ESM V2 to generate the same plots. Load up the pre-trained model
    test_dataloader = DataLoader(test_dataset, batch_size=128, shuffle=False)
    train_dataloader = DataLoader(train_dataset, batch_size=128, shuffle=False)

    esm_v2_model = EsmClassifierV2()
    losses = esm_train(esm_v2_model, train_dataloader, n_epochs=100)

    output = esm_test(esm_v2_model, test_dataloader)

    # print('LOSS:', output['loss'])
    print('ACCURACY:', (output['preds'] == output['labels']).float().mean().item())

    # Label the data according to whether or not it was correctly or incorrectly classified. 
    correct = (output['preds'].numpy() == output['labels'].numpy())
    labels = ['correct' if x else 'incorrect' for x in correct]
    labels = np.array(labels)
     
    palette = {'correct':'green', 'incorrect':'red'}
    plot_embeddings(test_embeddings_prot5, labels=labels, title='Classifier predictions using Prot5 embeddings', n_points=300, filename=figure_dir + 'embeddings_prot5_with_prediction.png', palette=palette)


    


 